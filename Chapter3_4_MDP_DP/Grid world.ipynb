{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e8a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# written by Liangying, 4/8/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d662339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac0f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Grid():\n",
    "    def __init__(self, row, col, Action, Reward, discount, policy, terminal_states):\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.Reward = Reward\n",
    "        self.discount = discount\n",
    "        self.terminal_states = terminal_states\n",
    "        \n",
    "        self.values = np.zeros((self.row, self.col))\n",
    "        \n",
    "        if policy == 'random':\n",
    "            self.policy = 1 / len(Action)\n",
    "        elif policy == 'best':\n",
    "            self.policy = np.zeros((self.row, self.col), dtype = str)\n",
    "        \n",
    "        self.Action = {}\n",
    "        for i,act in enumerate(Action):\n",
    "            if act == 'left':\n",
    "                self.Action[act] = np.array([0,-1])  \n",
    "            if act == 'right':\n",
    "                self.Action[act] = np.array([0,1])\n",
    "            if act == 'up':\n",
    "                self.Action[act] = np.array([-1,0])\n",
    "            if act == 'down':\n",
    "                self.Action[act] = np.array([1,0])\n",
    "                \n",
    "    def terminal_states_check(self,loc):\n",
    "        for state in self.terminal_states:\n",
    "            if (state == loc).all():   #判断行与行之间是否相等\n",
    "                return True #执行到return语句时，会退出函数，return之后的语句不再执行\n",
    "        return False    \n",
    "        \n",
    "    def Policy_evaluation_two_array(self):\n",
    "        values_new = np.zeros((self.row, self.col))   #注意一定要初始化为0，因为我每来到一个新的State，这个新的State是未知的，我不知道它的值是多少，我需要通过行动来不断估计它的值\n",
    "        #for i,j in product(range(0,self.row), range(0,self.col):\n",
    "        for r in range(self.row):\n",
    "            for c in range(self.col):\n",
    "                for act in self.Action.values():\n",
    "                    if self.terminal_states_check([r,c]):\n",
    "                        break    # break只能跳出一层循环, continue只能跳出一次循环而不是一层循环\n",
    "                    else:\n",
    "                        [r_new, c_new] = np.array([r,c]) + act  #move ，必须是numpy创建的数组才能直接相加\n",
    "                        if r_new < 0 or c_new < 0 or r_new >= self.row or c_new >= self.col:\n",
    "                            values_new[r,c] += self.policy * (self.Reward + self.discount * self.values[r, c])   \n",
    "                        else:\n",
    "                            values_new[r,c] += self.policy * (self.Reward + self.discount * self.values[r_new, c_new])\n",
    "        delta = np.abs(self.values - values_new)\n",
    "        self.values = values_new   #注意，新的数组将成为下一轮旧的数组,或者可以理解为values_new就是个临时空间，用于存放更新完后的值，然后把新的值存到原来的全局变量self.values中去，这样就实现了全局上的就地更新\n",
    "                                   #为什么这里多了一步临时数组，因为它不像前面的多臂赌博机中只在一个元素上就地更新，这里是整个数组，如果在原数组操作会影响数组元素的更新迭代\n",
    "        return self.values,delta   # 这里更新的位置在循环的外面，要等都计算完了才更新\n",
    "    \n",
    "    # 因为概率转移是到多个状态去，自己状态的更新本身就需要+=，如果还保留着上一次迭代的状态值就会自己加自己，但是我们想要的是状态长期的回报，这个回报只包括r + v(s')，并不包括自己这个状态的本身价值。所以每次迭代需要\n",
    "    # 自己状态价值变为0，但是加上别处的状态价值。所以要用一个临时变量values_new，这个变量每次都初始化为0，然后加上上一次其余状态的全局变量，再将这个临时变量传到自己状态这个全局变量中去。\n",
    "    \n",
    "    def Policy_evaluation_in_place(self):\n",
    "        #for i,j in product(range(0,self.row), range(0,self.col):\n",
    "        values_old = self.values.copy()   # 1、使用 = 直接赋值，是引用赋值，如果更改一个，另一个也会变，不管是更改a还是b，都会对对方产生影响；\n",
    "                                          # 2、使用copy()，是复制一个副本，不管更改哪一个，都不会影响到对方。\n",
    "        for r in range(self.row):\n",
    "            for c in range(self.col):\n",
    "                v = 0       #注意初始化\n",
    "                for act in self.Action.values():\n",
    "                    if self.terminal_states_check([r,c]):\n",
    "                        break    # break只能跳出一层循环\n",
    "                    else:\n",
    "                        [r_new, c_new] = np.array([r,c]) + act  #move ，必须是numpy创建的数组才能直接相加\n",
    "                        if r_new < 0 or c_new < 0 or r_new >= self.row or c_new >= self.col:\n",
    "                            v += self.policy * (self.Reward + self.discount * self.values[r, c])\n",
    "                        else:\n",
    "                            v += self.policy * (self.Reward + self.discount * self.values[r_new, c_new])\n",
    "                self.values[r,c] = v    # 注意更新的位置，不需要等所有矩阵都计算完后才更新，所以不需要一个临时的矩阵，而是一个变量即可。一边更新一边计算。\n",
    "        delta = np.abs(values_old - self.values)\n",
    "        return self.values,delta\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def Policy_str_to_ndarry(self,pi_str):\n",
    "        if pi_str == 'l':\n",
    "            return np.array([0,-1])  \n",
    "        if pi_str == 'r':\n",
    "            return np.array([0,1])\n",
    "        if pi_str == 'u':\n",
    "            return np.array([-1,0])\n",
    "        if pi_str == 'd':\n",
    "            return np.array([1,0])\n",
    "    \n",
    "        \n",
    "    def Policy_iteration(self):\n",
    "        self.policy = np.full((self.row, self.col),dtype = str,fill_value = 'l') # 对每个state，将初始策略任意初始化为向左走，但是要除去terminal state！\n",
    "        self.policy[0,0] = ''\n",
    "        self.policy[self.row-1, self.col-1] = ''\n",
    "        \n",
    "        while(True):\n",
    "            # Policy evaluation_in place\n",
    "            while(True):\n",
    "                values_old = self.values.copy()\n",
    "                for r in range(self.row):\n",
    "                    for c in range(self.col):\n",
    "                        if self.terminal_states_check([r,c]):\n",
    "                            continue\n",
    "                        else:\n",
    "                            [r_new, c_new] = np.array([r,c]) + self.Policy_str_to_ndarry(self.policy[r,c])\n",
    "                            if r_new < 0 or c_new < 0 or r_new >= self.row or c_new >= self.col:\n",
    "                                self.values[r,c] = self.Reward + self.discount * self.values[r, c]\n",
    "                            else:\n",
    "                                self.values[r,c] = self.Reward + self.discount * self.values[r_new, c_new]\n",
    "                delta = np.abs(values_old - self.values)\n",
    "                if np.max(delta) < 1e-4:\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            # Policy improvement\n",
    "            policy_old = self.policy.copy()\n",
    "            policy_stable = True\n",
    "            for r in range(self.row):\n",
    "                for c in range(self.col):\n",
    "                    v_actions = np.zeros(len(self.Action))\n",
    "                    for i,act in enumerate(self.Action.values()):\n",
    "                        if self.terminal_states_check([r,c]):\n",
    "                            break    \n",
    "                        else:\n",
    "                            [r_new, c_new] = np.array([r,c]) + act \n",
    "                            if r_new < 0 or c_new < 0 or r_new >= self.row or c_new >= self.col:\n",
    "                                v_actions[i] = self.Reward + self.discount * self.values[r, c]\n",
    "                            else:\n",
    "                                v_actions[i] = self.Reward + self.discount * self.values[r_new, c_new]\n",
    "                    if not self.terminal_states_check([r,c]):\n",
    "                        best_action = np.argmax(v_actions)\n",
    "                        self.policy[r,c] = list(self.Action)[best_action]  #获取单个key\n",
    "                        if self.policy[r,c] != policy_old[r,c]:\n",
    "                            policy_stable = False\n",
    "                        \n",
    "            if policy_stable:\n",
    "                return self.policy\n",
    "                break\n",
    "                \n",
    "        \n",
    "        \n",
    "    def Value_iteration(self):\n",
    "        values_old = self.values.copy()\n",
    "        for r in range(self.row):\n",
    "            for c in range(self.col):\n",
    "                v_actions = np.zeros(len(self.Action))\n",
    "                for i,act in enumerate(self.Action.values()):    \n",
    "                    if self.terminal_states_check([r,c]):\n",
    "                        break    # break只能跳出一层循环\n",
    "                    else:\n",
    "                        [r_new, c_new] = np.array([r,c]) + act  #move ，必须是numpy创建的数组才能直接相加\n",
    "                        if r_new < 0 or c_new < 0 or r_new >= self.row or c_new >= self.col:\n",
    "                            v_actions[i] = self.Reward + self.discount * self.values[r, c]\n",
    "                        else:\n",
    "                            v_actions[i] = self.Reward + self.discount * self.values[r_new, c_new]\n",
    "                if not self.terminal_states_check([r,c]):   #注意python中的逻辑运算符是and,or,not。不是!,~之类的与C相似的符号\n",
    "                    v_best_action = np.max(v_actions)\n",
    "                    best_action = np.argmax(v_actions)\n",
    "                    self.policy[r,c] = list(self.Action)[best_action]  #获取单个key\n",
    "                    self.values[r,c] = v_best_action\n",
    "        delta = np.abs(values_old - self.values)\n",
    "        return self.values, self.policy, delta\n",
    "        \n",
    "        \n",
    "    \n",
    "    def draw_fig(self, values):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_axis_off()\n",
    "        plt.table(cellText = values,loc = 'center', cellLoc = 'center')\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    row = 4\n",
    "    col = 4\n",
    "    Action = ['left','right','up','down']\n",
    "    Reward = -1\n",
    "    discount = 1\n",
    "    policy = 'random'\n",
    "    terminal_states = np.array([[0,0],[row-1,col-1]])   \n",
    "    grid = Grid(row, col, Action, Reward, discount, policy, terminal_states)\n",
    "    \n",
    " \n",
    "    flag = 1\n",
    "    while(flag):\n",
    "        #values,delta = grid.Policy_iteration_two_array()\n",
    "        values,delta = grid.Policy_evaluation_in_place()\n",
    "        #pdb.set_trace()\n",
    "        if np.max(delta) < 1e-4:\n",
    "            grid.draw_fig(np.around(values,2))\n",
    "            flag = 0\n",
    "            \n",
    "    policy = 'best'\n",
    "    grid = Grid(row, col, Action, Reward, discount, policy, terminal_states)\n",
    "    flag = 1\n",
    "    while(flag):\n",
    "        values,policy,delta = grid.Value_iteration()\n",
    "        if np.max(delta) < 1e-4:\n",
    "            grid.draw_fig(policy)\n",
    "            flag = 0\n",
    "            \n",
    "            \n",
    "    policy = 'best'\n",
    "    discount = 0.8    #如果初始化不是random，比如都向左，一定要使discount小于1，否则无法收敛！！\n",
    "    grid = Grid(row, col, Action, Reward, discount, policy, terminal_states)\n",
    "    policy = grid.Policy_iteration()\n",
    "    grid.draw_fig(policy)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6699e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['left', 'right', 'up', 'down'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.Action.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f007d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': array([ 0, -1]),\n",
       " 'right': array([0, 1]),\n",
       " 'up': array([-1,  0]),\n",
       " 'down': array([1, 0])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c4fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left [ 0 -1]\n",
      "right [0 1]\n",
      "up [-1  0]\n",
      "down [1 0]\n"
     ]
    }
   ],
   "source": [
    "for key,act in grid.Action.items():\n",
    "    print(key,act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "196e27ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(grid.Action)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e340683",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full((3, 3),dtype = str,fill_value = 'l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfa6e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (3,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Miniconda3\\envs\\jupyter_3.9\\lib\\site-packages\\numpy\\core\\numeric.py:344\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    342\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    343\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order)\n\u001b[1;32m--> 344\u001b[0m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mcopyto\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (3,3)"
     ]
    }
   ],
   "source": [
    "b = np.full((3,3), fill_value = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f34bcb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['', '', ''],\n",
       "       ['', '', ''],\n",
       "       ['', '', '']], dtype='<U1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f542829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['l', 'l', 'l'],\n",
       "       ['l', 'l', 'l'],\n",
       "       ['l', 'l', 'l']], dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5da0a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function full in module numpy:\n",
      "\n",
      "full(shape, fill_value, dtype=None, order='C', *, like=None)\n",
      "    Return a new array of given shape and type, filled with `fill_value`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or sequence of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    fill_value : scalar or array_like\n",
      "        Fill value.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array  The default, None, means\n",
      "         ``np.array(fill_value).dtype``.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether to store multidimensional data in C- or Fortran-contiguous\n",
      "        (row- or column-wise) order in memory.\n",
      "    like : array_like\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "    \n",
      "        .. versionadded:: 1.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of `fill_value` with the given shape, dtype, and order.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    empty : Return a new uninitialized array.\n",
      "    ones : Return a new array setting values to one.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.full((2, 2), np.inf)\n",
      "    array([[inf, inf],\n",
      "           [inf, inf]])\n",
      "    >>> np.full((2, 2), 10)\n",
      "    array([[10, 10],\n",
      "           [10, 10]])\n",
      "    \n",
      "    >>> np.full((2, 2), [1, 2])\n",
      "    array([[1, 2],\n",
      "           [1, 2]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b35f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_3.9] *",
   "language": "python",
   "name": "conda-env-jupyter_3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
