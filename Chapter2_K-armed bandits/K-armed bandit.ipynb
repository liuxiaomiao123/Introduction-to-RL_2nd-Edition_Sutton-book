{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08602513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# written by Liangying, 3/31/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3c1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdf26c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the number of bandits: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Bandit():\n",
    "    def __init__(self, k_arm=10, bandit_type='Gaussian'):\n",
    "        self.k_arm = k_arm\n",
    "        self.bandit_type = bandit_type\n",
    "        self.Q = np.zeros(self.k_arm)\n",
    "        if self.bandit_type == 'Gaussian':\n",
    "            self.mean = np.random.normal(0,1,self.k_arm)   #因为self.mean是全局变量，所以同一个bandit不需要设seed，这样就能保证不同run之间的分布是一样的。但是不同bandit需要重新设的\n",
    "            self.arm_best = np.argmax(self.mean) \n",
    "                \n",
    "    def reset(self):\n",
    "        self.action_count = np.zeros(self.k_arm, dtype='int')\n",
    "        self.Q = np.zeros(self.k_arm)\n",
    "        self.time = 0\n",
    "        self.R_avg_tmp = 0\n",
    "        self.action_best_tmp = 0 \n",
    "        \n",
    "    def pull_arm(self, time, method='Greedy'):\n",
    "        self.time = time\n",
    "        if method == 'Greedy':\n",
    "            #initial_reward = int(input(\"Please enter the number of initial reward for all arms: \"))\n",
    "            initial_reward = 0\n",
    "            if self.time == 0:\n",
    "                self.Q = [initial_reward]*self.k_arm\n",
    "            return np.argmax(self.Q)\n",
    "            \n",
    "        if method == 'Epsilon-Greedy':\n",
    "            #epsilon = int(input(\"Please enter the number of Epsilon: \"))\n",
    "            epsilon = 0.1\n",
    "            return np.random.choice([np.argmax(self.Q), np.random.randint(1,self.k_arm)], p=[1-epsilon, epsilon])\n",
    "            \n",
    "        if method == 'UCB':\n",
    "            #c = int(input(\"Please enter the number of the parameter c: \"))\n",
    "            c = 2\n",
    "            for i in range(self.k_arm):\n",
    "                self.Q[i] = self.Q[i] + c* np.sqrt(np.log(self.time+1) / self.action_count[i])  \n",
    "            return np.argmax(self.Q)\n",
    "            \n",
    "        if method == 'Gradient Bandit':\n",
    "            pass\n",
    "        \n",
    "        if method == 'Thompson Sampling':\n",
    "            pass\n",
    "        \n",
    "    def update_reward(self, action):\n",
    "        self.action_count[action] += 1\n",
    "        if action == self.arm_best:\n",
    "            self.action_best_tmp += (1 - self.action_best_tmp) / (self.time+1)\n",
    "        \n",
    "        R = np.random.normal(loc = self.mean[action], scale= 1.0,size = (1))\n",
    "        self.Q[action] += (R - self.Q[action]) / self.action_count[action]\n",
    "        self.R_avg_tmp += (R - self.R_avg_tmp) / (self.time+1)\n",
    "        \n",
    "        return self.R_avg_tmp, self.action_best_tmp\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #n_bandit = int(input(\"Please enter the number of bandits: \"))\n",
    "    #n_arm = int(input(\"Please enter the number of arms for each bandit: \"))\n",
    "    #n_run = int(input(\"Please enter the number of runs: \"))\n",
    "    #n_time = int(input(\"Please enter the number of timesteps: \"))\n",
    "    #bandit_type = input(\"Please enter the type of bandits: \")\n",
    "    \n",
    "    bandit_type = 'Gaussian'\n",
    "    n_arm = 10\n",
    "    n_run = 1\n",
    "    n_time = 1000\n",
    "    n_bandit = 1\n",
    "    \n",
    "    R_avg = np.zeros((n_bandit,n_run, n_time))\n",
    "    Best_action = np.zeros((n_bandit,n_run, n_time))   #float\n",
    "\n",
    "\n",
    "    for b in range(n_bandit):\n",
    "        bandit = Bandit(n_arm, bandit_type) \n",
    "        for r in range(n_run):\n",
    "            bandit.reset()\n",
    "            for t in range(n_time):\n",
    "                Action = bandit.pull_arm(method='Epsilon-Greedy', time=t)   #这个action不需要被类里的方法调用，所以可以写在外面，但是action_count需要，所以要在类里面就定义\n",
    "                Rt_avg,At_best = bandit.update_reward(Action)                           \n",
    "                R_avg[b,r,t] = Rt_avg\n",
    "                Best_action[b,r,t] = At_best\n",
    "    \n",
    "    R_avg_mean = np.mean(np.mean(R_avg,0),0)\n",
    "    Best_action_mean = np.mean(np.mean(Best_action,0),0) \n",
    "    \n",
    "    #print(bandit.arm_best)\n",
    "    #print(Best_action)\n",
    "        \n",
    "    plt.scatter(np.arange(n_time),R_avg_mean,c='green',marker='o',s=3)\n",
    "    #plt.scatter(np.arange(n_time),Best_action_mean,c='green',marker='o',s=3)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('average reward')\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8356366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de2541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176e4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存使用： 79466496\n",
      "总内存： 8156008448\n",
      "内存占比： 90.0\n",
      "CPU个数： 8\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "info = psutil.virtual_memory()\n",
    "print('内存使用：',psutil.Process(os.getpid()).memory_info().rss)\n",
    "print('总内存：',info.total)\n",
    "print('内存占比：',info.percent)\n",
    "print('CPU个数：',psutil.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1abd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    def __init__(self, k_arm=10, bandit_type='Gaussian'):\n",
    "        self.k_arm = k_arm\n",
    "        self.bandit_type = bandit_type\n",
    "        self.Q = np.zeros(k_arm)\n",
    "        if self.bandit_type == 'Gaussian':\n",
    "            self.mean = np.random.normal(0,1,self.k_arm)   #因为self.mean是全局变量，所以同一个bandit不需要设seed，这样就能保证不同run之间的分布是一样的。但是不同bandit需要重新设的\n",
    "        self.action_count = np.zeros(self.k_arm, dtype='int')\n",
    "        \n",
    "    def reset():\n",
    "        self.action_count = np.zeros(self.k_arm, dtype='int')\n",
    "        self.Q = np.zeros(k_arm)\n",
    "        self.time = 0\n",
    "        \n",
    "    def pull_arm(self, time, method='Greedy'):\n",
    "        self.time = time\n",
    "        if method == 'Greedy':\n",
    "            #initial_reward = int(input(\"Please enter the number of initial reward for all arms: \"))\n",
    "            initial_reward = 0\n",
    "            if self.time == 0:\n",
    "                self.Q = [initial_reward]*self.k_arm\n",
    "            return np.argmax(self.Q)\n",
    "            \n",
    "        if method == 'Epsilon-Greedy':\n",
    "            #epsilon = int(input(\"Please enter the number of Epsilon: \"))\n",
    "            epsilon = 0.1\n",
    "            return np.random.choice([np.argmax(self.Q), np.random.randint(1,self.k_arm)], p=[1-epsilon, epsilon])\n",
    "          \n",
    "            \n",
    "        if method == 'UCB':\n",
    "            #c = int(input(\"Please enter the number of the parameter c: \"))\n",
    "            c = 2\n",
    "            for i in range(self.k_arm):\n",
    "                self.Q[i] = self.Q[i] + c* np.sqrt(np.log(self.time+1) / self.action_count[i])  #这里可能有错误\n",
    "            return np.argmax(self.Q)\n",
    "            \n",
    "        if method == 'Gradient Bandit':\n",
    "            pass\n",
    "        \n",
    "        if method == 'Thompson Sampling':\n",
    "            pass\n",
    "        \n",
    "    def update_reward(self, action):\n",
    "        self.action_count[action] += 1\n",
    "        R = np.random.normal(loc = self.mean[action], scale= 1.0,size = (1))\n",
    "        self.Q[action] += (R - self.Q[action]) / self.action_count[action]\n",
    "        return R\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #n_bandit = int(input(\"Please enter the number of bandits: \"))\n",
    "    #n_arm = int(input(\"Please enter the number of arms for each bandit: \"))\n",
    "    #n_run = int(input(\"Please enter the number of runs: \"))\n",
    "    #n_time = int(input(\"Please enter the number of timesteps: \"))\n",
    "    #bandit_type = input(\"Please enter the type of bandits: \")\n",
    "    n_arm = 10\n",
    "    bandit_type = 'Gaussian'\n",
    "    n_run = 2000\n",
    "    n_time = 1000\n",
    "    \n",
    "    R_avg = np.zeros(n_time)\n",
    "    R_avg_tmp = 0\n",
    "    Best_action = np.zeros(n_time)\n",
    "    \n",
    "    bandit = Bandit(n_arm, bandit_type)\n",
    "\n",
    "    for t in range(n_time):\n",
    "        Action = bandit.pull_arm(method='Epsilon-Greedy', time=t)   #这个action不需要被类里的方法调用，所以可以写在外面，但是action_count需要，所以要在类里面就定义\n",
    "        Rt = bandit.update_reward(Action)                           \n",
    "        R_avg_tmp += (Rt - R_avg_tmp)/(t + 1)\n",
    "        R_avg[t] = R_avg_tmp\n",
    "        \n",
    "        #R_avg[t+1] += (Rt - R_avg[t])/(t + 1)                    \n",
    "        \n",
    "        #所有与time有关的数组都在主函数中进行定义赋值，因为time本身就是循环，而类定义的是一次的动作。除了Q和action_count(这两个都把time给消掉了，只保留最新的值)\n",
    "        # 一定要注意，这里是R_avg[t+1]而不是R_avg[t]，因为这里是按照时间点t去更新的；\n",
    "        # 为什么Q[t]而不是Q[t+1]呢？因为Q是按照arm更新的，本身就已经含有t的信息，相当于不断地在同一个位置更新值。而R_avg是在下一个位置更新值。\n",
    "        # 可以通过这个方法判断下标是否正确：当我想要更新值时，当前位置的值如果为0 或 初始值则说明要+1，如果当前位置的值是上一个历史的值则正确\n",
    "        \n",
    "        # 但是你会发现这样写就要判断t+1的边界，代码就冗长了。我们可以把它放到类里用一个全局的临时变量存储，然后再在循环中直接赋值。\n",
    "        # 因为一个全局变量,（它可以是类里的self，也可以是普通的不会被重复初始化的变量,但是如果要运行不同的run，必须要写在类里），就意味着我不断地在这个位置进行更新，这个位置的当前值就包含了历史。\n",
    "        # 由于Reward_avg与Arm无关，所以只需要一个公共的位置。不像Q需要k个公共的位置。\n",
    "        \n",
    "        # 我们最后的结果只需要R_avg和Best action，所以很多不需要用数组存储中间过程。\n",
    "        \n",
    "    #print(Action)\n",
    "    print(bandit.mean)\n",
    "    plt.scatter(np.arange(n_time),R_avg,c='green',marker='o',s=3)\n",
    "    #plt.scatter(np.arange(n_arm),bandit.Q,c='green',marker='o',s=3)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('average reward')\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请比较这三种不同的写法，掌握写代码的简洁性技巧。其中一个重要原则就是，不需要保存的中间结果全部用一个临时变量存储，放到for循环里不断地更新，而不是用数组存下来，很容易出现内存不足的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1573cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit():\n",
    "    def __init__(self, k_arm=10, bandit_type='Gaussian',n_timesteps=1000):\n",
    "        self.k_arm = k_arm\n",
    "        self.bandit_type = bandit_type\n",
    "        self.Q = np.zeros(k_arm)\n",
    "        if self.bandit_type == 'Gaussian':\n",
    "            self.mean = np.random.normal(0,1,self.k_arm)\n",
    "        self.action = np.zeros(n_timesteps, dtype='int')\n",
    "        self.action_count = np.zeros(self.k_arm, dtype='int')\n",
    "        self.avg_reward = np.zeros(n_timesteps)\n",
    "        \n",
    "    def pull_arm(self, time, method='Greedy'):\n",
    "        self.time = time\n",
    "        if method == 'Greedy':\n",
    "            #initial_reward = int(input(\"Please enter the number of initial reward for all arms: \"))\n",
    "            initial_reward = 0\n",
    "            if self.time == 0:\n",
    "                self.Q = [initial_reward]*self.k_arm\n",
    "            self.action[self.time] = np.argmax(self.Q)\n",
    "            \n",
    "        if method == 'Epsilon-Greedy':\n",
    "            #epsilon = int(input(\"Please enter the number of Epsilon: \"))\n",
    "            epsilon = 0.1\n",
    "            self.action[self.time] = np.random.choice([np.argmax(self.Q), np.random.randint(1,self.k_arm)], p=[1-epsilon, epsilon])\n",
    "          \n",
    "            \n",
    "        if method == 'UCB':\n",
    "            #c = int(input(\"Please enter the number of the parameter c: \"))\n",
    "            c = 2\n",
    "            Q_UCB = np.zeros(self.k_arm)\n",
    "            for i in range(self.k_arm):\n",
    "                count = np.sum(self.action[0:self.time+1] == i)\n",
    "                Q_UCB[i] = self.Q[i] + c* np.sqrt(np.log(self.time+1) / count)\n",
    "            self.action[self.time] = np.argmax(Q_UCB)\n",
    "            \n",
    "        if method == 'Gradient Bandit':\n",
    "            pass\n",
    "        \n",
    "        if method == 'Thompson Sampling':\n",
    "            pass\n",
    "        \n",
    "    def update_reward(self):\n",
    "        arm = self.action[self.time]\n",
    "        R = np.random.normal(loc = self.mean[arm] , scale= 1.0,size = (1))\n",
    "        count = np.sum(self.action[0:self.time+1] == arm)\n",
    "        self.Q[arm] += 1/count * (R - self.Q[arm])\n",
    "        try:\n",
    "            self.avg_reward[self.time+1] = self.avg_reward[self.time] + (R-self.avg_reward[self.time]) / (self.time+1)\n",
    "        except:\n",
    "            self.time -=1                   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #n_bandit = int(input(\"Please enter the number of bandits: \"))\n",
    "    #n_arm = int(input(\"Please enter the number of arms for each bandit: \"))\n",
    "    #n_run = int(input(\"Please enter the number of runs: \"))\n",
    "    #n_time = int(input(\"Please enter the number of timesteps: \"))\n",
    "    #bandit_type = input(\"Please enter the type of bandits: \")\n",
    "    n_arm = 10\n",
    "    bandit_type = 'Gaussian'\n",
    "    n_time = 1000\n",
    "    \n",
    "    bandit = Bandit(n_arm, bandit_type, n_time)\n",
    "    for t in range(n_time):\n",
    "        bandit.pull_arm(method='Greedy', time=t)\n",
    "        bandit.update_reward()\n",
    "\n",
    "    plt.scatter(np.arange(n_time),bandit.avg_reward,c='green',marker='o',s=3)\n",
    "    #plt.scatter(np.arange(10),bandit.Q,c='green',marker='o',s=3)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('average reward')\n",
    "    plt.show()        \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_3.9] *",
   "language": "python",
   "name": "conda-env-jupyter_3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
